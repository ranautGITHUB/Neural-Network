Neural Networks Coursework
This repository contains my university coursework for Neural Networks. It includes assignments and small projects that explore important Machine Learning concepts and different model architectures.
Project 1: Logistic Regression as a Single-Layer Perceptron
Goal:
The aim of this project is to build a basic binary classifier using TensorFlow and understand how a single artificial neuron makes predictions.
Technical Overview
Model Structure: One input layer with two features connected to a single output neuron.
Activation Function: Sigmoid function, which converts the output into a probability value between 0 and 1.
Optimization Method: Adam optimizer.
Loss Function: Binary Cross-Entropy.
Main Concepts Covered: Model weights, gradient calculation, backpropagation, and linear decision boundaries.
Output and Learning Behavior
During training, the model gradually learns to separate two classes of data by drawing a straight decision boundary. As gradient descent updates the weights, the loss value decreases and the accuracy improves over time.
Environment and Execution
All notebooks and scripts in this repository are designed to run on Google Colab to prevent compatibility issues, especially with newer Python versions.
How to Run the Project
Open Google Colab.
Upload the .ipynb or .py file from this repository.
Run all cells to observe the training process and visualize the results.
This project demonstrates the foundational principles behind neural networks by showing how even a single neuron can perform classification tasks effectively.
